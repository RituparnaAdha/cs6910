# -*- coding: utf-8 -*-
"""Partaq5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UP1qISXEEZNWMv5h6iKYSnTKfUyDLexu
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras import models, optimizers, activations
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model

#to test on small dataset
from google.colab import drive
drive.mount('/content/drive')
import os
!ls

os.chdir('drive/My Drive/dl_cs6910/Assignment2')
!ls

cnn_model = tf.keras.models.load_model('best_model')
cnn_model.summary()



def generate_data(directory, data_desc, data_aug, batch_size, image_shape):
    if(data_desc == "test"):
        data = ImageDataGenerator(rescale=1./255)
        data = data.flow_from_directory(
            directory,
            target_size=image_shape,
            color_mode="rgb",
            batch_size=batch_size,
            class_mode="categorical",
            shuffle=True,
            seed=42
        )
        return data
    else:
        if data_aug:
            data = ImageDataGenerator(featurewise_center = True,
                                      brightness_range=None,
                                      width_shift_range=0.2,
                                      height_shift_range=0.2, 
                                      shear_range=0.2,
                                      zoom_range=0.2,
                                      horizontal_flip=True,
                                      rotation_range=30,
                                      fill_mode='reflect',
                                      rescale=1./255,
                                      validation_split=0.1
            )
        else:
            data = ImageDataGenerator(rescale=1./255, validation_split=0.1)
            
        train_data = data.flow_from_directory(
            directory,
            target_size=image_shape,
            color_mode="rgb",
            batch_size=batch_size,
            class_mode="categorical",
            shuffle=True,
            seed=42,
            subset="training"
        )
        
        val_data = data.flow_from_directory(
            directory,
            target_size=image_shape,
            color_mode="rgb",
            batch_size=batch_size,
            class_mode="categorical",
            shuffle=True,
            seed=42,
            subset="validation"
        )
        return train_data, val_data

class_names = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']

data_aug = [True]
batch_size = 32
image_shape = (128,128)
test_data_dir = 'inaturalist_12K/val/'
test = generate_data(test_data_dir, "test", data_aug[0], batch_size, image_shape)

for i in range(len(cnn_model.layers)):
    layer = cnn_model.layers[i]
    if 'conv' not in layer.name:
        continue
    # get filter weights
    filters, biases = layer.get_weights()
    print(i, layer.name, filters.shape, layer.input.shape, layer.output.shape)

guided_model = Model(inputs=cnn_model.inputs, outputs=cnn_model.layers[20].output)

@tf.custom_gradient
def guidedRelu(x):
    def grad(dy):
        return tf.cast(dy>0,"float32") * tf.cast(x>0, "float32") * dy
    return tf.nn.relu(x), grad

layer_dict = [layer for layer in guided_model.layers[1:] if hasattr(layer,'activation')]
for layer in layer_dict:
    layer.activation = guidedRelu

image, label = test.next()
plt.imshow(image[0])



with tf.GradientTape() as tape:
    inputs = tf.cast(image, tf.float32)
    tape.watch(inputs)
    outputs = guided_model(inputs)
    
grads = tape.gradient(outputs,inputs)

plt.imshow(grads[0])

#Visualizing the guided back prop
guided_back_prop = grads[0]
gb_viz = np.dstack((
            guided_back_prop[:, :, 0],
            guided_back_prop[:, :, 1],
            guided_back_prop[:, :, 2],
        ))       
gb_viz -= np.min(gb_viz)
gb_viz /= gb_viz.max()
    
imgplot = plt.imshow(gb_viz)
plt.axis("off")
plt.show()

x_list = []
y_list = []
z_list = []
grads = []
while len(grads)!= 10:
    
    x = np.random.randint(4)
    y = np.random.randint(4)
    z = np.random.randint(4)
    
    single_neuron_model = Model(inputs=cnn_model.inputs, outputs=cnn_model.layers[20].output[:,x,y,z])
    
    layer_dict = [layer for layer in single_neuron_model.layers[1:] if hasattr(layer,'activation')]
    for layer in layer_dict:
        layer.activation = guidedRelu
    
    with tf.GradientTape() as tape:
        inputs = tf.cast(image, tf.float32)
        tape.watch(inputs)
        outputs = single_neuron_model(inputs)
        
    if outputs.numpy()[0] != 0:
        grads.append(tape.gradient(outputs,inputs))
        x_list.append(x)
        y_list.append(y)
        z_list.append(z)

single_neuron_model = Model(inputs=cnn_model.inputs, outputs=cnn_model.layers[20].output)
    
layer_dict = [layer for layer in single_neuron_model.layers[1:] if hasattr(layer,'activation')]
for layer in layer_dict:
    layer.activation = guidedRelu

with tf.GradientTape() as tape:
    inputs = tf.cast(image, tf.float32)
    tape.watch(inputs)
    outputs = single_neuron_model(inputs)
    print(len(outputs))

plt.figure(figsize=(25, 10))
for i in range(10):
    ax = plt.subplot(2, 5, i + 1)
    plt.imshow(grads[i][0])
    # plt.title("Neuron Index - (" + str(x_list[i]) + "," + str(y_list[i]) + "," + str(z_list[i]) + ")")
    plt.axis("off")

plt.figure(figsize=(25, 10))
for i in range(10):
    guided_back_prop = grads[i][0]
    gb_viz = np.dstack((
                guided_back_prop[:, :, 0],
                guided_back_prop[:, :, 1],
                guided_back_prop[:, :, 2],
            ))       
    gb_viz -= np.min(gb_viz)
    gb_viz /= gb_viz.max()
    ax = plt.subplot(2, 5, i + 1)
    plt.imshow(gb_viz)
    plt.title("Neuron Index - (" + str(x_list[i]) + "," + str(y_list[i]) + "," + str(z_list[i]) + ")")
    plt.axis("off")

