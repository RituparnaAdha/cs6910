# -*- coding: utf-8 -*-
"""partaq5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C2C47MzQWZyu8FRjxaeJAeBhe4Xrr9QO
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras import models, optimizers, activations
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model

!pip install wandb

!wandb login

import wandb
wandb.init(project='assignment2_partA_Q5', entity='shreekanti')

#to test on small dataset
from google.colab import drive
drive.mount('/content/drive')
!ls

import os
os.chdir('drive/My Drive/dl_cs6910/Assignment2')
!ls

# Recreate the exact same model, including its weights and the optimizer
# cnn_model = tf.keras.models.load_model('best_model')
cnn_model = tf.keras.models.load_model('model-best.h5')
cnn_model.summary()

def generate_data(directory, data_desc, data_aug, batch_size, image_shape):
    if(data_desc == "test"):
        data = ImageDataGenerator(rescale=1./255)
        data = data.flow_from_directory(
            directory,
            target_size=image_shape,
            color_mode="rgb",
            batch_size=batch_size,
            class_mode="categorical",
            shuffle=True,
            seed=42
        )
        return data
    else:
        if data_aug:
            data = ImageDataGenerator(featurewise_center = True,
                                      brightness_range=None,
                                      width_shift_range=0.2,
                                      height_shift_range=0.2, 
                                      shear_range=0.2,
                                      zoom_range=0.2,
                                      horizontal_flip=True,
                                      rotation_range=30,
                                      fill_mode='reflect',
                                      rescale=1./255,
                                      validation_split=0.1
            )
        else:
            data = ImageDataGenerator(rescale=1./255, validation_split=0.1)
            
        train_data = data.flow_from_directory(
            directory,
            target_size=image_shape,
            color_mode="rgb",
            batch_size=batch_size,
            class_mode="categorical",
            shuffle=True,
            seed=42,
            subset="training"
        )
        
        val_data = data.flow_from_directory(
            directory,
            target_size=image_shape,
            color_mode="rgb",
            batch_size=batch_size,
            class_mode="categorical",
            shuffle=True,
            seed=42,
            subset="validation"
        )
        return train_data, val_data

data_aug = [True]
batch_size = 64
image_shape = (227,227)
test_data_dir = 'inaturalist_12K/val/'
test = generate_data(test_data_dir, "test", data_aug[0], batch_size, image_shape)
class_names = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']

#fetching images of one batch size for which we are going to do guided back propagation
image, label = test.next()
# print(len(image))
plt.figure(figsize=(25, 25))
wandb_img = []
wandb_title = [] 
for i in range(len(image)):
  ax = plt.subplot(8, int(len(image)/8),i+1)
  wandb_img.append(image[i])
  wandb_title.append(class_names[np.argmax(label[i])]) 
  plt.imshow(image[i])
  plt.title(class_names[np.argmax(label[i])])
  plt.axis("off")

 
for j in range(len(wandb_img)):
  wandb.log({"Images of one batch size": [wandb.Image(wandb_img[j], caption=wandb_title[j])]})

# for i in range(len(cnn_model.layers)):
#     layer = cnn_model.layers[i]
#     print(i, layer.name, layer.input.shape, layer.output.shape)

print(cnn_model.inputs)
print(cnn_model.layers[20].output)

@tf.custom_gradient
def guidedRelu(x):
    def grad(dy):
        return tf.cast(dy>0,"float32") * tf.cast(x>0, "float32") * dy
    return tf.nn.relu(x), grad

#guided model for the inut image
guided_model = Model(inputs=cnn_model.inputs, outputs=cnn_model.layers[20].output)

# replacing relu to guided relu function because we dont want negetive value to flow back
layer_dict = [layer for layer in guided_model.layers[1:] if hasattr(layer,'activation')]
for layer in layer_dict:
    layer.activation = guidedRelu

#calculating gradient for each input image
with tf.GradientTape() as tape:
    inputs = tf.cast(image, tf.float32)
    tape.watch(inputs)
    outputs = guided_model(inputs)
grads = tape.gradient(outputs,inputs)
#64 image: batch size of 64
print(np.shape(grads))

#ploting the gradient of each input image
maxValue = np.amax(grads[0])
minValue = np.amin(grads[0])
# print(maxValue)
# print(minValue)
#value pixel avalues are range from -ve to +ve so
dOutput_dInput = grads
wandb_img = []
wandb_title = [] 
plt.figure(figsize=(25, 25))
for i in range(len(dOutput_dInput)):
  ax = plt.subplot(8, int(len(dOutput_dInput)/8),i+1)
  image_ = np.clip(dOutput_dInput[i], 0, 1)
  wandb_img.append(image_)
  wandb_title.append(class_names[np.argmax(label[i])]) 
  plt.imshow(image_)
  plt.title(class_names[np.argmax(label[i])])
  plt.axis("off")

for j in range(len(wandb_img)):
  wandb.log({"Image(Gradient) of Input image": [wandb.Image(wandb_img[j], caption=wandb_title[j])]})

#Visualizing the guided back prop
plt.figure(figsize=(25, 25))
for i in range(len(dOutput_dInput)):
  back_prop_grad = dOutput_dInput[i]
  back_prop_visual = np.dstack(( back_prop_grad[:, :, 0], back_prop_grad[:, :, 1], back_prop_grad[:, :, 2]))
  back_prop_visual -= np.min(back_prop_visual)
  back_prop_visual /= back_prop_visual.max()

  ax = plt.subplot(8, int(len(dOutput_dInput)/8),i+1)
  image_ = np.clip(back_prop_visual, 0, 1)
  plt.imshow(image_)
  plt.title(class_names[np.argmax(label[i])])
  plt.axis("off")

output_shape = cnn_model.layers[20].output.shape
print(output_shape[1])
print(output_shape[2])
print(output_shape[3])
print(cnn_model.inputs[0].shape)
print(cnn_model.layers[20].output.shape)
print(cnn_model.layers[20].output[:,1,1,1])

#Guided back propagation for any(random) 10 neurons in the CONV5 layer
X, Y, Z, grads = [], [], [], []
while len(grads)!= 10:
    x = np.random.randint(output_shape[1])
    y = np.random.randint(output_shape[2])
    z = np.random.randint(output_shape[3])

    single_neuron_model = Model(inputs=cnn_model.inputs, outputs=cnn_model.layers[20].output[:,x,y,z])
    
    layer_dict = [layer for layer in single_neuron_model.layers[1:] if hasattr(layer,'activation')]
    for layer in layer_dict:
        layer.activation = guidedRelu
    
    with tf.GradientTape() as tape:
        inputs = tf.cast(image, tf.float32)
        tape.watch(inputs)
        outputs = single_neuron_model(inputs)
        
    if outputs.numpy()[0] != 0:
        grads.append(tape.gradient(outputs,inputs))
        X.append(x)
        Y.append(y)
        Z.append(z)

np.shape(grads[:10])

def plot_img(row, column,range_k, images, indexes, title,figsize,wandb_id):
  wandb_img = []
  wandb_title = []
  plt.figure(figsize = figsize)
  for k in range(range_k):
    ax = plt.subplot(row, column,k+1)
    image_img = images[k]
    wandb_img.append(image_img)
    wandb_title.append(title + indexes[k])
    plt.imshow(image_img)
    plt.title(title + indexes[k])
    plt.axis("off") 
  for j in range(len(wandb_img)):
    wandb.log({wandb_id: [wandb.Image(wandb_img[j], caption=wandb_title[j])]})

for i in range(len(dOutput_dInput)):
# for i in range(2):
    image_ = np.clip(dOutput_dInput[i], 0, 1)
    plot_img(1,1,1,[image_]," ",class_names[np.argmax(label[i])], (3,3), "Gradient of input neurons")
    # ploting gradient of each images
    image_ = []
    index_ = []
    for j in range(10):
      image_.append(np.clip(grads[j][i], 0, 1))
      index_.append("("+str(X[j]) + "," + str(Y[j]) + "," + str(Z[j])+")")
    plot_img(1,10,10,image_,index_,"index: ",(20,20), "Gradient of input neurons")

for i in range(len(dOutput_dInput)):
# for i in range(2):
  image_ = np.clip(dOutput_dInput[i], 0, 1)
  plot_img(1,1,1,[image_]," ",class_names[np.argmax(label[i])], (3,3), "Back prop visualizarion")
  image_ = []
  index_ = []
  for j in range(10):
    guided_back_prop = grads[j][i]
    back_prop_visual = np.dstack((guided_back_prop[:, :, 0],guided_back_prop[:, :, 1], guided_back_prop[:, :, 2]))     
    back_prop_visual -= np.min(back_prop_visual)
    back_prop_visual /= back_prop_visual.max()
    image_.append(np.clip(back_prop_visual, 0, 1))
    index_.append("("+str(X[j]) + "," + str(Y[j]) + "," + str(Z[j])+")")
  plot_img(1,10,10,image_,index_, "index: ", (25,25), "Back prop visualizarion")

